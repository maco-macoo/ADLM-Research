[project]
name = "adlm"
version = "0.1.0"
description = "Add your description here"
requires-python = ">=3.9,<3.10"
dependencies = [
    "datasets==2.18.0",
    "einops==0.7.0",
    "fsspec==2024.2.0",
    "git-lfs==1.6",
    "h5py==3.10.0",
    "hydra-core==1.3.2",
    "ipdb==0.13.13",
    "lightning==2.2.1",
    "mauve-text==0.4.0",
    "notebook==7.1.1",
    "nvitop==1.3.2",
    "omegaconf==2.3.0",
    "packaging==23.2",
    "pandas==2.2.1",
    "rich==13.7.1",
    "scikit-learn==1.4.0",
    "seaborn==0.13.2",
    "timm==0.9.16",
    "torch==2.7.1+cu128",
    "torchvision==0.22.1+cu128",
    "transformers==4.38.2",
    "wandb==0.13.5",
    "flash-attn @ https://github.com/Dao-AILab/flash-attention/releases/download/v2.6.3/flash_attn-2.6.3+cu123torch2.4cxx11abiTRUE-cp39-cp39-linux_x86_64.whl",
]

[tool.uv.sources]
torch = [
    { index = "torch-cu128" },
]
torchvision = [
    { index = "torch-cu128" },
]

[[tool.uv.index]]
name = "torch-cu128"
url = "https://download.pytorch.org/whl/cu128"
explicit = true
